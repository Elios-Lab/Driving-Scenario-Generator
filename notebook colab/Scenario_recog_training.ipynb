{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Scenario_recog_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm7Pg7yDqUu4"
      },
      "source": [
        "The VideoFrameGenerator I created can be installed via pip command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dvWuAPpfmvq"
      },
      "source": [
        "%cd /content/\n",
        "import os\n",
        "os.mkdir(\"Dataset\") \n",
        "os.mkdir(\"Testset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HK1iUAB83vP"
      },
      "source": [
        "# Download\n",
        "#dataset\n",
        "%cd /content/Dataset\n",
        "#!curl -L \"Link for rar file here\" > Dataset.rar; unrar x Dataset.rar; rm Dataset.rar  \n",
        "\n",
        "#testset\n",
        "%cd /content/Testset\n",
        "#!curl -L \"Link for rar file here\" > Testset.rar; unrar x Testset.rar; rm Testset.rar  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zcu69A4thvZ"
      },
      "source": [
        "%cd /content\n",
        "!rm -r chkp/\n",
        "!rm -r logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiUUdcFQoIJA"
      },
      "source": [
        "!pip install keras-video-generators\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqRyinYdpCeg"
      },
      "source": [
        "%cd /content/\n",
        "import os\n",
        "import glob\n",
        "import keras\n",
        "from keras_video import VideoFrameGenerator\n",
        "# use sub directories names as classes\n",
        "classes = [i.split(os.path.sep)[1] for i in glob.glob('Dataset/*')]\n",
        "classes.sort()\n",
        "# some global params\n",
        "SIZE = (112, 112)\n",
        "CHANNELS = 3\n",
        "NBFRAME = 10\n",
        "BS = 8\n",
        "# pattern to get videos and classes\n",
        "glob_pattern='Dataset/{classname}/*.mp4'\n",
        "# for data augmentation\n",
        "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
        "    zoom_range=.1,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=8,\n",
        "    width_shift_range=.2,\n",
        "    height_shift_range=.2)\n",
        "# Create video frame generator\n",
        "train = VideoFrameGenerator(\n",
        "    classes=classes, \n",
        "    glob_pattern=glob_pattern,\n",
        "    nb_frames=NBFRAME,\n",
        "    split_val=.2,\n",
        "    shuffle=True,\n",
        "    batch_size=BS,\n",
        "    target_shape=SIZE,\n",
        "    nb_channel=CHANNELS,\n",
        "    transformation=data_aug,\n",
        "    use_frame_cache=False)\n",
        "\n",
        "import keras_video.utils\n",
        "valid = train.get_validation_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXKpxWBJqebU"
      },
      "source": [
        "To get the validation data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmMH7qmKqk9G"
      },
      "source": [
        "Here are samples from train generator — you can use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvVxe9h6pMWO"
      },
      "source": [
        "import keras_video.utils\n",
        "keras_video.utils.show_sample(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECEQ4rxrqoYW"
      },
      "source": [
        "So, we need to create that ConvNet. I recommend creating a function that returns the model. Here, I’m using a simple model. I made several convolutions with batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRlPbCh4pV_I"
      },
      "source": [
        "from keras.layers import Conv2D, BatchNormalization, \\\n",
        "    MaxPool2D, GlobalMaxPool2D\n",
        "def build_convnet(shape=(112, 112, 3)):\n",
        "    momentum = .9\n",
        "    model = keras.Sequential()\n",
        "    model.add(Conv2D(64, (3,3), input_shape=shape,\n",
        "        padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    model.add(MaxPool2D())\n",
        "    \n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    model.add(MaxPool2D())\n",
        "    \n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    model.add(MaxPool2D())\n",
        "    \n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # flatten...\n",
        "    model.add(GlobalMaxPool2D())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6PAq5QZqr8Q"
      },
      "source": [
        "OK, it’s now time to build the time distributed model. I was using LSTM that is very efficient, but I finally use GRU that is conceptually the same but using less memory, but the cost is that it is less efficient. But one more time, we’re testing…"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajPNZ38ApYn0"
      },
      "source": [
        "from keras.layers import TimeDistributed, GRU, Dense, Dropout, LSTM\n",
        "def action_model(shape=(NBFRAME, 112, 112, CHANNELS), nbout=3):\n",
        "    # Create our convnet with (112, 112, 3) input shape\n",
        "    convnet = build_convnet(shape[1:])\n",
        "    convnet.summary()\n",
        "    \n",
        "    # then create our final model\n",
        "    model = keras.Sequential()\n",
        "    # add the convnet with (5, 112, 112, 3) shape\n",
        "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "    # here, you can also use GRU or LSTM\n",
        "    model.add(GRU(64))\n",
        "    # and finally, we make a decision network\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(nbout, activation='softmax'))\n",
        "    return model\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4jVq76ZqweE"
      },
      "source": [
        "Because the dataset is not very large, I recommend using Dropout to avoid overfitting (it will happen anyway… but at least we reduce the problem)\n",
        "Let’s create the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHaUW2lUpc-n"
      },
      "source": [
        "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (5, 112, 112, 3)\n",
        "model = action_model(INSHAPE, len(classes))\n",
        "optimizer = keras.optimizers.Adam(0.001)\n",
        "model.compile(\n",
        "    optimizer,\n",
        "    'categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_TfBj6RpllR"
      },
      "source": [
        "# #Training\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIwz2zLTpe8v"
      },
      "source": [
        "EPOCHS=200\n",
        "# create a \"chkp\" directory before to run that\n",
        "# because ModelCheckpoint will write models inside\n",
        "#keras.callbacks.EarlyStopping(monitor=\"acc\", patience=10),\n",
        "callbacks = [\n",
        "    keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        'chkp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
        "        verbose=1),\n",
        "        keras.callbacks.TensorBoard(log_dir='logs')\n",
        "]\n",
        "model.fit(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbgLEUsb8wzR"
      },
      "source": [
        "%cd /content\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n",
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG09dmiovLeO"
      },
      "source": [
        "#   Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql_koda4oDFn"
      },
      "source": [
        "create testset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_SiG5I5oAzi"
      },
      "source": [
        "%cd /content/\n",
        "import os\n",
        "import glob\n",
        "import keras\n",
        "from keras_video import VideoFrameGenerator\n",
        "# use sub directories names as classes\n",
        "classes = [i.split(os.path.sep)[1] for i in glob.glob('Testset/*')]\n",
        "classes.sort()\n",
        "# some global params\n",
        "SIZE = (112, 112)\n",
        "CHANNELS = 3\n",
        "NBFRAME = 10\n",
        "BS = 8\n",
        "# pattern to get videos and classes\n",
        "glob_pattern='Testset/{classname}/*.mp4'\n",
        "# for data augmentation\n",
        "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
        "    zoom_range=.1,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=8,\n",
        "    width_shift_range=.2,\n",
        "    height_shift_range=.2)\n",
        "# Create video frame generator\n",
        "test_gen = VideoFrameGenerator(\n",
        "    classes=classes, \n",
        "    glob_pattern=glob_pattern,\n",
        "    nb_frames=NBFRAME,\n",
        "    shuffle=False,\n",
        "    split_val=.99,\n",
        "    batch_size=BS,\n",
        "    target_shape=SIZE,\n",
        "    nb_channel=CHANNELS,\n",
        "    transformation=data_aug,\n",
        "    use_frame_cache=False)\n",
        "\n",
        "import keras_video.utils\n",
        "test = test_gen.get_validation_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0_9TC7_oIHm"
      },
      "source": [
        "custom show_result method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUANyibSQFV4"
      },
      "source": [
        "\"\"\"\n",
        "Utils module to provide some nice functions to develop with Keras and\n",
        "Video sequences.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def custom_show_sample(pred, g, index=0, random=False, row_width=22, row_height=5):\n",
        "    \"\"\" Displays a batch using matplotlib.\n",
        "\n",
        "    params:\n",
        "\n",
        "    - g: keras video generator\n",
        "    - index: integer index of batch to see (overriden if random is True)\n",
        "    - random: boolean, if True, take a random batch from the generator\n",
        "    - row_width: integer to give the figure height\n",
        "    - row_height: integer that represents one line of image, it is multiplied by \\\n",
        "    the number of sample in batch.\n",
        "    \"\"\"\n",
        "    total = len(g)\n",
        "    sample = index\n",
        "    batch_offset = BS*(index)\n",
        "\n",
        "    assert index < len(g)\n",
        "    sample = g[sample]\n",
        "    sequences = sample[0]\n",
        "    labels = sample[1]\n",
        "    classes = ['Approach', 'ChangeLane', 'Follow', 'FreeRide']\n",
        "    rows = len(sequences)\n",
        "    index = 1\n",
        "    fig = plt.figure(figsize=(row_width, row_height*rows))\n",
        "    for batchid, sequence in enumerate(sequences):\n",
        "        classid = np.argmax(labels[batchid])\n",
        "        classname = g.classes[classid]\n",
        "        cols = len(sequence)\n",
        "        pred_acc = np.argmax(pred, axis=1)\n",
        "        pred_index = pred_acc[batchid + batch_offset]\n",
        "        for image in sequence:\n",
        "            plt.subplot(rows, cols, index)\n",
        "            plt.title(classname)\n",
        "            plt.imshow(image)\n",
        "            plt.annotate(classes[pred_index], xy=(0, 100))\n",
        "            acc = pred[batchid + batch_offset]\n",
        "            acc_str = []\n",
        "            for i in range(len(acc)):\n",
        "              k = \"{:.2f}\".format(acc[i])\n",
        "              acc_str.append(float(k))\n",
        "            plt.annotate(acc_str, xy=(30, 90))\n",
        "            plt.axis('off')\n",
        "            index += 1\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw-64pAiAmq5"
      },
      "source": [
        "custom method for printing results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr9EJ85m_cCb"
      },
      "source": [
        "def print_results(results):\n",
        "  #print(results)\n",
        "  result_class= np.argmax(results, axis=1)\n",
        "  print(result_class)\n",
        "\n",
        "  #print confidenc of each prediction\n",
        "  seq = -1\n",
        "  seq_batch = -1\n",
        "  batch = 0\n",
        "  classes = ['Approach', 'ChangeLane', 'Follow', 'FreeRide']\n",
        "\n",
        "\n",
        "  for conf in results:\n",
        "    seq = seq + 1\n",
        "    seq_batch = seq_batch + 1\n",
        "    if (seq % (BS ) == 0 and seq != 0):\n",
        "      seq_batch = seq_batch - (BS )\n",
        "    if (seq % (BS ) == 0 and seq != 0):\n",
        "      batch = batch + 1\n",
        "    #print('seq',seq)\n",
        "    #print('seq_batch',seq_batch)\n",
        "    #print('batch',batch)\n",
        "    acc_str = []\n",
        "    for i in range(len(conf)):\n",
        "      k = \"{:.2f}\".format(conf[i])\n",
        "      acc_str.append(float(k))\n",
        "    print('sequence ',seq )\n",
        "    classid = np.argmax(test[batch][1][seq_batch -1])\n",
        "    print('correct class:', classes[classid], ' - ', 'prediction:', classes[result_class[seq]])\n",
        "    print('confidence: ', acc_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77hNN27RoHC7"
      },
      "source": [
        "Accuracy e visual output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T59J8dwiNNS"
      },
      "source": [
        "import numpy as np\n",
        "#compute and print average accuracy\n",
        "accuracy = model.evaluate(test)\n",
        "#compute and print predictions\n",
        "results = model.predict(test)\n",
        "\n",
        "#print results\n",
        "print_results(results)\n",
        "  \n",
        "#show results\n",
        "batch = len(test)\n",
        "for i in range(batch):\n",
        "  custom_show_sample(results, test,i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GbWeNhjCqBo"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mbVoXWBCsSL"
      },
      "source": [
        "#Copy chkp to GDrive\n",
        "#!cp \"/content/chkp/weights.150-0.53.hdf5\" -r \"/content/gdrive/My Drive/\"\n",
        "#!cp \"/content/chkp/weights.140-0.53.hdf5\" -r \"/content/gdrive/My Drive/\"\n",
        "\n",
        "#Copy logs to GDrive\n",
        "#!cp \"/content/gdrive/MyDrive/100%/day_cut_20frame_full_95%/logs\" -r \"/content/logs\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}